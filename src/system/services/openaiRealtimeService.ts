/**
 * OpenAI Realtime API Service - WebRTC Edition
 * Service pour g√©rer la connexion WebRTC avec l'API Realtime d'OpenAI
 * Utilise l'interface unifi√©e recommand√©e par OpenAI pour les navigateurs
 *
 * Architecture:
 * - Le client cr√©e un RTCPeerConnection
 * - Envoie le SDP offer au backend (/session)
 * - Le backend retourne le SDP answer d'OpenAI
 * - Connexion WebRTC peer-to-peer automatique
 * - Audio g√©r√© automatiquement par WebRTC
 * - √âv√©nements via RTCDataChannel
 */

import logger from '../../lib/utils/logger';
import type { ChatMode } from '../store/globalChatStore';
import type { VoiceType } from '../store/voiceCoachStore';

interface RealtimeConfig {
  model: string;
  voice: VoiceType;
  temperature?: number;
  maxTokens?: number;
  instructions?: string;
}

interface RealtimeMessage {
  type: string;
  [key: string]: any;
}

type MessageHandler = (message: RealtimeMessage) => void;
type ErrorHandler = (error: Error) => void;
type ConnectionHandler = () => void;

class OpenAIRealtimeService {
  private peerConnection: RTCPeerConnection | null = null;
  private dataChannel: RTCDataChannel | null = null;
  private config: RealtimeConfig | null = null;
  private isConnected = false;
  private messageHandlers: Set<MessageHandler> = new Set();
  private errorHandlers: Set<ErrorHandler> = new Set();
  private connectHandlers: Set<ConnectionHandler> = new Set();
  private disconnectHandlers: Set<ConnectionHandler> = new Set();
  private audioElement: HTMLAudioElement | null = null;
  private localStream: MediaStream | null = null;

  /**
   * Initialiser la connexion WebRTC √† l'API Realtime via l'interface unifi√©e
   */
  async connect(config: RealtimeConfig): Promise<void> {
    if (this.isConnected && this.peerConnection) {
      logger.info('REALTIME_WEBRTC', '‚úÖ Already connected, skipping');
      return;
    }

    this.config = config;

    try {
      logger.info('REALTIME_WEBRTC', 'üöÄ STARTING WEBRTC CONNECTION TO REALTIME API', {
        model: config.model,
        voice: config.voice,
        temperature: config.temperature,
        maxTokens: config.maxTokens,
        timestamp: new Date().toISOString()
      });

      // V√©rifier la configuration Supabase
      const supabaseUrl = import.meta.env.VITE_SUPABASE_URL;
      const supabaseAnonKey = import.meta.env.VITE_SUPABASE_ANON_KEY;

      logger.info('REALTIME_WEBRTC', 'üîç Environment variables check', {
        hasSupabaseUrl: !!supabaseUrl,
        supabaseUrlLength: supabaseUrl?.length || 0,
        hasSupabaseAnonKey: !!supabaseAnonKey,
        supabaseAnonKeyLength: supabaseAnonKey?.length || 0
      });

      if (!supabaseUrl || !supabaseAnonKey) {
        const missingVars = [];
        if (!supabaseUrl) missingVars.push('VITE_SUPABASE_URL');
        if (!supabaseAnonKey) missingVars.push('VITE_SUPABASE_ANON_KEY');

        logger.error('REALTIME_WEBRTC', '‚ùå Missing Supabase configuration', {
          missingVariables: missingVars
        });
        throw new Error(`Supabase configuration missing: ${missingVars.join(', ')}`);
      }

      // V√©rifier le support WebRTC
      if (typeof RTCPeerConnection === 'undefined') {
        logger.error('REALTIME_WEBRTC', '‚ùå WebRTC not available in this environment');
        throw new Error('WebRTC API is not available in this browser/environment');
      }

      logger.info('REALTIME_WEBRTC', '‚úÖ WebRTC API is available');

      // Cr√©er le RTCPeerConnection
      logger.info('REALTIME_WEBRTC', 'üîå Creating RTCPeerConnection...');
      this.peerConnection = new RTCPeerConnection();

      logger.info('REALTIME_WEBRTC', '‚úÖ RTCPeerConnection created', {
        connectionState: this.peerConnection.connectionState,
        iceConnectionState: this.peerConnection.iceConnectionState
      });

      // Configurer l'√©l√©ment audio pour la lecture
      this.audioElement = document.createElement('audio');
      this.audioElement.autoplay = true;
      logger.info('REALTIME_WEBRTC', 'üîä Audio element created and configured');

      // G√©rer les tracks audio entrants (de l'API OpenAI)
      this.peerConnection.ontrack = (event) => {
        logger.info('REALTIME_WEBRTC', 'üì• Received remote audio track', {
          streamId: event.streams[0]?.id,
          trackKind: event.track.kind,
          trackId: event.track.id
        });

        if (this.audioElement && event.streams[0]) {
          this.audioElement.srcObject = event.streams[0];
          logger.info('REALTIME_WEBRTC', '‚úÖ Audio stream connected to audio element');
        }
      };

      // Obtenir le flux audio local (microphone)
      logger.info('REALTIME_WEBRTC', 'üé§ Requesting microphone access...');
      try {
        this.localStream = await navigator.mediaDevices.getUserMedia({
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true,
            sampleRate: 24000,
            channelCount: 1
          }
        });

        logger.info('REALTIME_WEBRTC', '‚úÖ Microphone access granted', {
          trackCount: this.localStream.getTracks().length,
          tracks: this.localStream.getTracks().map(t => ({
            kind: t.kind,
            label: t.label,
            enabled: t.enabled
          }))
        });

        // Ajouter le track audio local au peer connection
        this.localStream.getTracks().forEach(track => {
          if (this.peerConnection && this.localStream) {
            this.peerConnection.addTrack(track, this.localStream);
            logger.info('REALTIME_WEBRTC', '‚úÖ Local audio track added to peer connection', {
              trackKind: track.kind,
              trackId: track.id
            });
          }
        });
      } catch (micError) {
        logger.error('REALTIME_WEBRTC', '‚ùå Failed to get microphone access', {
          error: micError instanceof Error ? micError.message : String(micError)
        });
        throw new Error('Microphone access required for voice sessions');
      }

      // Cr√©er le data channel pour les √©v√©nements
      logger.info('REALTIME_WEBRTC', 'üì° Creating data channel for events...');
      this.dataChannel = this.peerConnection.createDataChannel('oai-events');

      this.setupDataChannelHandlers();

      // G√©rer les √©v√©nements de connexion
      this.setupConnectionHandlers();

      // Cr√©er l'offer SDP
      logger.info('REALTIME_WEBRTC', 'üìù Creating SDP offer...');
      const offer = await this.peerConnection.createOffer();
      await this.peerConnection.setLocalDescription(offer);

      logger.info('REALTIME_WEBRTC', '‚úÖ SDP offer created and set as local description', {
        sdpType: offer.type,
        sdpLength: offer.sdp?.length || 0
      });

      // Envoyer le SDP offer au backend pour obtenir le SDP answer d'OpenAI
      const sessionUrl = `${supabaseUrl}/functions/v1/voice-coach-realtime/session`;

      logger.info('REALTIME_WEBRTC', 'üåê Sending SDP offer to backend', {
        url: sessionUrl
      });

      const response = await fetch(sessionUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${supabaseAnonKey}`,
          'apikey': supabaseAnonKey
        },
        body: JSON.stringify({
          sdp: offer.sdp,
          model: config.model,
          voice: config.voice,
          instructions: config.instructions
        })
      });

      if (!response.ok) {
        const errorText = await response.text();
        logger.error('REALTIME_WEBRTC', '‚ùå Backend returned error', {
          status: response.status,
          statusText: response.statusText,
          error: errorText
        });
        throw new Error(`Failed to create session: ${response.status} - ${errorText}`);
      }

      // R√©cup√©rer le SDP answer
      const sdpAnswer = await response.text();
      logger.info('REALTIME_WEBRTC', '‚úÖ Received SDP answer from backend', {
        sdpAnswerLength: sdpAnswer.length
      });

      // D√©finir le SDP answer comme remote description
      const answer: RTCSessionDescriptionInit = {
        type: 'answer',
        sdp: sdpAnswer
      };

      await this.peerConnection.setRemoteDescription(answer);
      logger.info('REALTIME_WEBRTC', '‚úÖ SDP answer set as remote description');

      // Attendre que la connexion soit √©tablie
      logger.info('REALTIME_WEBRTC', '‚è≥ Waiting for connection to establish...');
      await this.waitForConnection();

      logger.info('REALTIME_WEBRTC', '‚úÖ‚úÖ‚úÖ SUCCESSFULLY CONNECTED TO REALTIME API VIA WEBRTC ‚úÖ‚úÖ‚úÖ');

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      const errorStack = error instanceof Error ? error.stack : undefined;

      logger.error('REALTIME_WEBRTC', '‚ùå‚ùå‚ùå CONNECTION FAILED ‚ùå‚ùå‚ùå', {
        errorMessage,
        errorStack,
        connectionState: this.peerConnection?.connectionState,
        iceConnectionState: this.peerConnection?.iceConnectionState
      });

      // Nettoyer en cas d'erreur
      this.cleanup();

      throw error;
    }
  }

  /**
   * Attendre que la connexion WebRTC soit √©tablie
   */
  private async waitForConnection(): Promise<void> {
    return new Promise<void>((resolve, reject) => {
      const startTime = Date.now();
      const timeout = 15000; // 15 secondes

      const checkConnection = () => {
        if (!this.peerConnection) {
          reject(new Error('Peer connection lost'));
          return;
        }

        const state = this.peerConnection.connectionState;
        const iceState = this.peerConnection.iceConnectionState;

        logger.debug('REALTIME_WEBRTC', 'Checking connection state', {
          connectionState: state,
          iceConnectionState: iceState,
          elapsed: Date.now() - startTime
        });

        if (state === 'connected' || iceState === 'connected' || iceState === 'completed') {
          logger.info('REALTIME_WEBRTC', '‚úÖ Connection established', {
            connectionState: state,
            iceConnectionState: iceState,
            duration: Date.now() - startTime
          });
          this.isConnected = true;
          this.connectHandlers.forEach(handler => {
            try {
              handler();
            } catch (error) {
              logger.error('REALTIME_WEBRTC', 'Error in connection handler', { error });
            }
          });
          resolve();
          return;
        }

        if (state === 'failed' || iceState === 'failed') {
          logger.error('REALTIME_WEBRTC', '‚ùå Connection failed', {
            connectionState: state,
            iceConnectionState: iceState
          });
          reject(new Error('WebRTC connection failed'));
          return;
        }

        if (Date.now() - startTime > timeout) {
          logger.error('REALTIME_WEBRTC', '‚ùå Connection timeout', {
            connectionState: state,
            iceConnectionState: iceState,
            duration: Date.now() - startTime
          });
          reject(new Error('Connection timeout'));
          return;
        }

        // R√©essayer apr√®s un court d√©lai
        setTimeout(checkConnection, 100);
      };

      checkConnection();
    });
  }

  /**
   * Configurer les handlers du data channel
   */
  private setupDataChannelHandlers(): void {
    if (!this.dataChannel) return;

    this.dataChannel.onopen = () => {
      logger.info('REALTIME_WEBRTC', '‚úÖ Data channel opened');
    };

    this.dataChannel.onclose = () => {
      logger.info('REALTIME_WEBRTC', 'üîå Data channel closed');
    };

    this.dataChannel.onerror = (error) => {
      logger.error('REALTIME_WEBRTC', '‚ùå Data channel error', { error });
    };

    this.dataChannel.onmessage = (event) => {
      try {
        const message = JSON.parse(event.data) as RealtimeMessage;

        // Log des types de messages importants
        const importantTypes = [
          'session.updated',
          'conversation.item.input_audio_transcription.delta',
          'conversation.item.input_audio_transcription.completed',
          'response.audio_transcript.delta',
          'response.audio_transcript.done',
          'response.done',
          'error'
        ];

        if (importantTypes.includes(message.type)) {
          logger.info('REALTIME_WEBRTC', `üì® Important message: ${message.type}`, {
            type: message.type,
            hasContent: !!message.delta || !!message.transcript
          });
        }

        // Dispatcher aux handlers
        this.messageHandlers.forEach(handler => {
          try {
            handler(message);
          } catch (error) {
            logger.error('REALTIME_WEBRTC', 'Error in message handler', {
              error: error instanceof Error ? error.message : String(error),
              messageType: message.type
            });
          }
        });
      } catch (error) {
        logger.error('REALTIME_WEBRTC', 'Error parsing data channel message', {
          error: error instanceof Error ? error.message : String(error),
          data: event.data
        });
      }
    };
  }

  /**
   * Configurer les handlers de connexion
   */
  private setupConnectionHandlers(): void {
    if (!this.peerConnection) return;

    this.peerConnection.onconnectionstatechange = () => {
      const state = this.peerConnection?.connectionState;
      logger.info('REALTIME_WEBRTC', `Connection state changed: ${state}`);

      if (state === 'failed' || state === 'closed' || state === 'disconnected') {
        this.isConnected = false;
        this.disconnectHandlers.forEach(handler => {
          try {
            handler();
          } catch (error) {
            logger.error('REALTIME_WEBRTC', 'Error in disconnect handler', { error });
          }
        });

        if (state === 'failed') {
          const error = new Error('WebRTC connection failed');
          this.errorHandlers.forEach(handler => {
            try {
              handler(error);
            } catch (handlerError) {
              logger.error('REALTIME_WEBRTC', 'Error in error handler', { handlerError });
            }
          });
        }
      }
    };

    this.peerConnection.oniceconnectionstatechange = () => {
      const state = this.peerConnection?.iceConnectionState;
      logger.info('REALTIME_WEBRTC', `ICE connection state changed: ${state}`);
    };

    this.peerConnection.onicegatheringstatechange = () => {
      const state = this.peerConnection?.iceGatheringState;
      logger.debug('REALTIME_WEBRTC', `ICE gathering state changed: ${state}`);
    };
  }

  /**
   * D√©connecter de l'API
   */
  disconnect(): void {
    logger.info('REALTIME_WEBRTC', 'Disconnecting...');
    this.cleanup();
  }

  /**
   * Nettoyer toutes les ressources
   */
  private cleanup(): void {
    // Fermer le data channel
    if (this.dataChannel) {
      this.dataChannel.close();
      this.dataChannel = null;
    }

    // Fermer la peer connection
    if (this.peerConnection) {
      this.peerConnection.close();
      this.peerConnection = null;
    }

    // Arr√™ter les tracks du stream local
    if (this.localStream) {
      this.localStream.getTracks().forEach(track => track.stop());
      this.localStream = null;
    }

    // Nettoyer l'√©l√©ment audio
    if (this.audioElement) {
      this.audioElement.srcObject = null;
      this.audioElement = null;
    }

    this.isConnected = false;

    logger.info('REALTIME_WEBRTC', 'Cleanup complete');
  }

  /**
   * Envoyer un message via le data channel
   */
  private sendMessage(message: RealtimeMessage): void {
    if (!this.dataChannel || this.dataChannel.readyState !== 'open') {
      logger.error('REALTIME_WEBRTC', '‚ùå Cannot send message: data channel not open', {
        hasDataChannel: !!this.dataChannel,
        readyState: this.dataChannel?.readyState,
        messageType: message.type
      });
      return;
    }

    try {
      this.dataChannel.send(JSON.stringify(message));
      logger.debug('REALTIME_WEBRTC', 'üì§ Message sent', {
        type: message.type
      });
    } catch (error) {
      logger.error('REALTIME_WEBRTC', '‚ùå Error sending message', {
        error: error instanceof Error ? error.message : String(error),
        messageType: message.type
      });
    }
  }

  /**
   * Configurer la session (pas n√©cessaire avec WebRTC, tout est dans le SDP)
   * Gard√© pour compatibilit√© mais ne fait rien
   */
  configureSession(systemPrompt: string, mode: ChatMode): void {
    logger.info('REALTIME_WEBRTC', '‚öôÔ∏è Session configuration handled by backend during connection', {
      mode,
      promptLength: systemPrompt.length
    });
    // Avec WebRTC + interface unifi√©e, la config est faite lors du POST /session
    // Pas besoin d'envoyer session.update
  }

  /**
   * Envoyer de l'audio (pas n√©cessaire avec WebRTC, g√©r√© automatiquement)
   * Gard√© pour compatibilit√© mais ne fait rien
   */
  sendAudio(audioData: ArrayBuffer): void {
    logger.debug('REALTIME_WEBRTC', 'Audio is handled automatically by WebRTC, ignoring manual send');
    // WebRTC g√®re l'audio automatiquement via les tracks
  }

  /**
   * Valider l'audio buffer (pas n√©cessaire avec WebRTC)
   * Gard√© pour compatibilit√© mais ne fait rien
   */
  commitAudioBuffer(): void {
    logger.debug('REALTIME_WEBRTC', 'Audio buffer commit not needed with WebRTC');
    // WebRTC g√®re tout automatiquement
  }

  /**
   * Annuler la r√©ponse en cours
   */
  cancelResponse(): void {
    this.sendMessage({
      type: 'response.cancel'
    });
    logger.debug('REALTIME_WEBRTC', 'Response cancellation requested');
  }

  /**
   * Envoyer un message texte
   */
  sendTextMessage(text: string): void {
    this.sendMessage({
      type: 'conversation.item.create',
      item: {
        type: 'message',
        role: 'user',
        content: [
          {
            type: 'input_text',
            text
          }
        ]
      }
    });

    // Demander une r√©ponse
    this.sendMessage({
      type: 'response.create'
    });

    logger.debug('REALTIME_WEBRTC', 'Text message sent', { text });
  }

  /**
   * Enregistrer des handlers d'√©v√©nements
   */
  onMessage(handler: MessageHandler): () => void {
    this.messageHandlers.add(handler);
    return () => this.messageHandlers.delete(handler);
  }

  onError(handler: ErrorHandler): () => void {
    this.errorHandlers.add(handler);
    return () => this.errorHandlers.delete(handler);
  }

  onConnect(handler: ConnectionHandler): () => void {
    this.connectHandlers.add(handler);
    return () => this.connectHandlers.delete(handler);
  }

  onDisconnect(handler: ConnectionHandler): () => void {
    this.disconnectHandlers.add(handler);
    return () => this.disconnectHandlers.delete(handler);
  }

  /**
   * Getters
   */
  get connected(): boolean {
    return this.isConnected;
  }

  get readyState(): number {
    if (!this.peerConnection) return 3; // CLOSED

    // Mapper les √©tats WebRTC aux √©tats WebSocket pour compatibilit√©
    const state = this.peerConnection.connectionState;
    switch (state) {
      case 'new':
      case 'connecting':
        return 0; // CONNECTING
      case 'connected':
        return 1; // OPEN
      case 'disconnected':
      case 'failed':
      case 'closed':
        return 3; // CLOSED
      default:
        return 3;
    }
  }
}

// Export singleton
export const openaiRealtimeService = new OpenAIRealtimeService();
