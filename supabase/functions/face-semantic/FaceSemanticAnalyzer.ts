// supabase/functions/face-semantic/faceSemanticAnalyzer.ts

interface PhotoReport {
  quality?: {
    blur_score: number;
    brightness: number;
    exposure_ok: boolean;
  };
  content?: {
    face_detected: boolean;
    face_bbox_norm: [number, number, number, number];
  };
}

interface AnalyzeOptions {
  gender: 'male' | 'female';
  frontReport?: PhotoReport;
  profileReport?: PhotoReport;
}

interface FaceSemanticResult {
  face_shape: string;
  eye_shape: string;
  nose_type: string;
  lip_fullness: string;
  confidence: {
    semantic: number;
    face_detection: number;
  };
  // Raw AI scores or features can be added here
  raw_ai_scores?: Record<string, number>;
}

/**
 * Simule l'analyse de photos avec une IA pour extraire les param√®tres s√©mantiques du visage.
 * Dans une impl√©mentation r√©elle, cela appellerait une API d'IA (ex: OpenAI Vision).
 */
export async function analyzePhotosForFaceSemantics(
  frontPhotoUrl: string,
  profilePhotoUrl: string,
  options: AnalyzeOptions
): Promise<FaceSemanticResult> {
  console.log('üîç [faceSemanticAnalyzer] Simulating AI analysis for face semantics (gpt-5-mini ready):', {
    frontPhotoUrl: frontPhotoUrl.substring(0, 50) + '...',
    profilePhotoUrl: profilePhotoUrl.substring(0, 50) + '...',
    gender: options.gender,
    hasFrontReport: !!options.frontReport,
    hasProfileReport: !!options.profileReport,
  });

  // --- D√âBUT DE LA PARTIE QUI SIMULERAIT UN APPEL OPENAI R√âEL ---
  // Dans une impl√©mentation r√©elle, vous feriez un appel fetch ici.
  // Par exemple:
  /*
  const openaiApiKey = Deno.env.get('OPENAI_API_KEY');
  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${openaiApiKey}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: 'gpt-5-mini', // MOD√àLE MIS √Ä JOUR VERS GPT-5 MINI
      messages: [
        {
          role: 'user',
          content: [
            { type: 'text', text: `Analyze the face in these images. Identify face shape, eye shape, nose type, and lip fullness. Gender: ${options.gender}. Return JSON.` },
            { type: 'image_url', image_url: { url: frontPhotoUrl, detail: 'high' } },
            { type: 'image_url', image_url: { url: profilePhotoUrl, detail: 'high' } }
          ]
        }
      ],
      response_format: { type: "json_object" },
      max_completion_tokens: 12000, // Increased to accommodate reasoning tokens (medium uses ~2-3K reasoning tokens)
      // Note: GPT-5 only supports default temperature (1) - parameter omitted to use default
      verbosity: 'low', // Simple structured output
      reasoning_effort: 'medium' // CORRECTED: Optimal balance for facial analysis, ~2-3K reasoning tokens (40-50% fewer than 'high')
    })
  });

  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(`OpenAI API error: ${response.status} - ${errorText}`);
  }
  const openaiResult = await response.json();
  // Traitez openaiResult pour extraire les param√®tres
  */
  // --- FIN DE LA PARTIE SIMUL√âE ---


  // Simuler un d√©lai d'analyse IA
  await new Promise(resolve => setTimeout(resolve, 1500));

  let faceShape: string;
  let eyeShape: string;
  let noseType: string;
  // MODIFIED: Utiliser une valeur valide de l'√©num√©ration de la base de donn√©es
  let lipFullness: string;
  let confidence = 0.85;

  if (options.gender === 'female') {
    faceShape = 'oval';
    eyeShape = 'almond';
    noseType = 'straight';
    lipFullness = 'average'; // MODIFIED: "average" est valide dans l'√©num√©ration DB
  } else {
    faceShape = 'square';
    eyeShape = 'round';
    noseType = 'roman';
    lipFullness = 'average'; // MODIFIED: "average" est valide dans l'√©num√©ration DB
  }

  // Ajuster la confiance en fonction de la qualit√© des photos si les rapports sont disponibles
  if (options.frontReport?.quality?.blur_score < 0.5 || options.profileReport?.quality?.blur_score < 0.5) {
    confidence -= 0.1;
  }
  if (!options.frontReport?.content?.face_detected || !options.profileReport?.content?.face_detected) {
    confidence -= 0.2;
  }

  const result: FaceSemanticResult = {
    face_shape: faceShape,
    eye_shape: eyeShape,
    nose_type: noseType,
    lip_fullness: lipFullness,
    confidence: {
      semantic: Math.max(0.1, confidence),
      face_detection: (options.frontReport?.content?.face_detected && options.profileReport?.content?.face_detected) ? 0.9 : 0.5,
    },
    raw_ai_scores: {
      // Exemple de scores bruts que l'IA pourrait retourner
      face_oval_score: options.gender === 'female' ? 0.9 : 0.3,
      face_square_score: options.gender === 'male' ? 0.85 : 0.2,
      eye_almond_score: options.gender === 'female' ? 0.8 : 0.4,
      nose_straight_score: 0.7,
      lip_full_score: options.gender === 'female' ? 0.75 : 0.4,
    }
  };

  console.log('‚úÖ [faceSemanticAnalyzer] Simulated AI analysis complete:', result);
  return result;
}

